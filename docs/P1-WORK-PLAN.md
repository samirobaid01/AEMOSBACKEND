# P1 Issues - Complete Work Plan & Implementation Strategy

## üéØ **Executive Summary**

**Sprint Goal**: Enhance performance, reliability, and observability of AEMOS Backend  
**Total Effort**: 7 days  
**Priority**: üü† High (P1)  
**Dependencies**: P0 issues completed ‚úÖ  
**Target Completion**: Sprint 2

---

## üì¶ **P1 Issues Overview**

| # | Issue | Effort | Impact | Priority | Status |
|---|-------|--------|--------|----------|--------|
| 1 | Optimize index with variable-level filtering + device support | 2.5 days | 10x speedup + 70% fewer executions | üü† P1 | Not Started |
| 2 | Add rule execution timeouts + error codes | 1.25 days | Prevent hangs + observability | üü† P1 | Not Started |
| 3 | Add Prometheus metrics (cardinality-safe) | 3 days | Observability | üü† P1 | Partial (P0) |
| 4 | Validate rule chain config UUIDs | 1 day | Security | üü† P1 | Not Started |

**Total**: 7.75 days across 4 issues

**üî¥ Critical Updates Based on Expert Review:**
- ‚úÖ **Device-level variable support** (sensors vs devices separation)
- ‚úÖ **Timeout error codes** (structured observability)
- ‚úÖ **Prometheus cardinality control** (prevent production issues)

**‚è≥ Deferred to P2:**
- AND-condition pre-filtering (measure production need first)
- RuleContext architecture (good but requires larger refactor)

---

# üé´ **Issue #1: Optimize Index with Variable-Level Filtering**

## JIRA Description

### Title
`[P1] Optimize Rule Chain Index with Variable-Level Filtering - 10x Speedup + 70% Fewer Executions`

### Type
`Performance Enhancement + Intelligent Filtering`

### Priority
`üü† High (P1)`

### Affected Components
- `src/ruleEngine/indexing/RuleChainIndex.js`
- `src/ruleEngine/core/RuleEngineEventBus.js`
- `src/controllers/dataStreamController.js`

### Problem Statement

**Current Behavior - Problem 1: Slow Cache Misses**
When a sensor UUID is not in Redis cache, the system performs a full table scan of **all** filter nodes:

```javascript
const buildIndexForSensor = async (sensorUUID) => {
  // ‚ùå Fetches ALL filter nodes in the system
  const nodes = await RuleChainNode.findAll({
    where: { type: 'filter' },
    attributes: ['ruleChainId', 'config']
  });
  
  // ‚ùå Iterates through ALL nodes in memory
  nodes.forEach((node) => {
    const uuids = extractSensorUuidsFromConfig(node.config);
    if (uuids.includes(sensorUUID)) {
      ruleChainIds.add(node.ruleChainId);
    }
  });
}
```

**Current Behavior - Problem 2: Unnecessary Rule Executions**
System triggers rule chains even when incoming telemetry doesn't have required variables:

```javascript
// Sensor "abc123" sends: {"humidity": 65, "pressure": 1013}
// Rule Chain has filter: sensorUUID="abc123" AND temperature > 30

// ‚ùå Problem: Rule chain is queued and executed even though 
// incoming data doesn't have "temperature" variable!
```

**Combined Impact:**
- **First request per sensor**: 50-200ms latency
- **Complexity**: O(N) where N = total filter nodes
- **Memory**: Loads all filter node configs into memory
- **Wasted executions**: 50-80% of rule chains process irrelevant data
- **Queue bloat**: Unnecessary jobs consume worker capacity

**Current Metrics** (estimated for 1000 filter nodes):
- Cache hit: ~2ms
- Cache miss: ~150ms (75x slower)
- Memory per miss: ~5-10MB
- Unnecessary rule executions: ~60% of total

### Inspiration: ThingsBoard Architecture

Inspired by [ThingsBoard's](https://thingsboard.io/) state-of-the-art approach:
- **Message Type Routing**: Filter by telemetry type
- **Originator + Data Key Filtering**: Match device UUID AND data keys present
- **Early Filter Evaluation**: Check conditions before heavy processing
- **Rule Chain Metadata**: Store required data keys with each rule chain

### Acceptance Criteria

- [ ] **AC1**: Cache miss latency reduced from 150ms to <15ms (10x improvement)
- [ ] **AC2**: Variable-level indexing: `(sensorUUID, variableName) ‚Üí [ruleChainIds]`
- [ ] **AC3**: Device-level indexing: `(deviceUUID, propertyName) ‚Üí [ruleChainIds]`
- [ ] **AC4**: Only trigger rule chains when incoming variables match filter requirements
- [ ] **AC5**: Unnecessary rule executions reduced by 50-80%
- [ ] **AC6**: Query uses MySQL JSON indexes instead of full table scan
- [ ] **AC7**: Memory usage during cache miss reduced by 90%
- [ ] **AC8**: Optional: Pre-build variable-level indexes on startup
- [ ] **AC9**: Separate namespaces for sensors (telemetry) vs devices (state)
- [ ] **AC10**: Unit tests cover sensors, devices, and mixed scenarios
- [ ] **AC11**: Performance benchmarks documented (latency + execution reduction)

### Technical Approach

#### **Solution: Variable-Level Index with MySQL JSON Optimization**

This solution combines **two optimizations**:
1. **MySQL JSON queries** for fast database-level filtering (10x speedup)
2. **Variable-level indexing** to eliminate unnecessary executions (70% reduction)

---

### **Part 1: Variable-Level Index Structure (Sensors + Devices)**

**üî¥ CRITICAL**: Separate namespaces for sensors (telemetry) vs devices (state)

**Index Format**:
```
rulechain:var:sensor:{sensorUUID}:{variableName} ‚Üí [ruleChainIds]
rulechain:var:device:{deviceUUID}:{propertyName} ‚Üí [ruleChainIds]
```

**Why Two Namespaces?**
- **Sensors** = Telemetry producers (read-only data: temperature, humidity, motion)
- **Devices** = Controllable entities (stateful properties: power, speed, mode)

**Example:**
```javascript
// Sensor rules (telemetry variables):
"rulechain:var:sensor:abc123:temperature" ‚Üí [1, 3, 5]
"rulechain:var:sensor:abc123:humidity" ‚Üí [1, 2]
"rulechain:var:sensor:abc123:motion" ‚Üí [4]

// Device rules (state properties):
"rulechain:var:device:xyz789:power" ‚Üí [6, 7]
"rulechain:var:device:xyz789:speed" ‚Üí [8]

// Incoming telemetry: {"temperature": 25}
// Lookup: rulechain:var:sensor:abc123:temperature
// Result: Trigger rule chains [1, 3, 5]

// Incoming device state: {"power": "on"}
// Lookup: rulechain:var:device:xyz789:power
// Result: Trigger rule chains [6, 7]
```

---

### **Part 2: Implementation with Sensor/Device Support**

```javascript
// src/ruleEngine/indexing/RuleChainIndex.js

const KEY_PREFIX_SENSOR = 'rulechain:var:sensor:';
const KEY_PREFIX_DEVICE = 'rulechain:var:device:';
const DEFAULT_TTL_SECONDS = 3600;

const buildIndexForOriginator = async (originatorType, originatorId) => {
  if (!originatorId || !originatorType) return new Map();
  
  const typeField = originatorType === 'sensor' ? 'sensorUUID' : 'deviceUUID';
  
  const query = `
    SELECT DISTINCT 
      ruleChainId,
      JSON_EXTRACT(config, '$.key') as variableName,
      JSON_EXTRACT(config, '$.sourceType') as sourceType
    FROM RuleChainNode
    WHERE type = 'filter'
      AND JSON_EXTRACT(config, '$.sourceType') = :originatorType
      AND (
        JSON_EXTRACT(config, '$.UUID') = :uuid OR
        JSON_EXTRACT(config, '$.uuid') = :uuid OR
        JSON_EXTRACT(config, '$.${typeField}') = :uuid
      )
  `;
  
  const nodes = await sequelize.query(query, {
    replacements: { 
      uuid: originatorId,
      originatorType,
      typeField
    },
    type: QueryTypes.SELECT
  });
  
  const variableIndex = new Map();
  nodes.forEach(node => {
    const varName = node.variableName?.replace(/"/g, '');
    if (varName) {
      if (!variableIndex.has(varName)) {
        variableIndex.set(varName, new Set());
      }
      variableIndex.get(varName).add(node.ruleChainId);
    }
  });
  
  const keyPrefix = originatorType === 'sensor' 
    ? KEY_PREFIX_SENSOR 
    : KEY_PREFIX_DEVICE;
  
  const pipeline = redisConnection.pipeline();
  for (const [varName, ruleChainIds] of variableIndex) {
    const key = `${keyPrefix}${originatorId}:${varName}`;
    pipeline.set(
      key, 
      JSON.stringify(Array.from(ruleChainIds)), 
      'EX', 
      DEFAULT_TTL_SECONDS
    );
  }
  await pipeline.exec();
  
  logger.debug(`Built ${originatorType} variable-level index`, {
    originatorId,
    variables: Array.from(variableIndex.keys()),
    totalRuleChains: new Set([...variableIndex.values()].flat()).size
  });
  
  return variableIndex;
};

const getRuleChainsForOriginator = async (originatorType, originatorId, variableNames = []) => {
  if (!originatorId || !originatorType) return [];
  
  if (variableNames.length === 0) {
    logger.warn(`getRuleChainsForOriginator called without variables`, {
      originatorType,
      originatorId
    });
    return [];
  }
  
  const keyPrefix = originatorType === 'sensor' 
    ? KEY_PREFIX_SENSOR 
    : KEY_PREFIX_DEVICE;
  
  const ruleChainIds = new Set();
  let needsRebuild = false;
  
  for (const varName of variableNames) {
    const key = `${keyPrefix}${originatorId}:${varName}`;
    
    try {
      const cached = await redisConnection.get(key);
      if (cached) {
        const ids = JSON.parse(cached);
        ids.forEach(id => ruleChainIds.add(id));
      } else {
        needsRebuild = true;
      }
    } catch (error) {
      logger.warn(`Failed to read index for ${originatorType}:${originatorId}:${varName}`, error);
      needsRebuild = true;
    }
  }
  
  if (needsRebuild) {
    const variableIndex = await buildIndexForOriginator(originatorType, originatorId);
    
    for (const varName of variableNames) {
      if (variableIndex.has(varName)) {
        variableIndex.get(varName).forEach(id => ruleChainIds.add(id));
      }
    }
  }
  
  return Array.from(ruleChainIds);
};

const invalidateOriginator = async (originatorType, originatorId) => {
  if (!originatorId || !originatorType) return;
  
  const keyPrefix = originatorType === 'sensor' 
    ? KEY_PREFIX_SENSOR 
    : KEY_PREFIX_DEVICE;
  
  const pattern = `${keyPrefix}${originatorId}:*`;
  const keys = await redisConnection.keys(pattern);
  
  if (keys.length > 0) {
    await redisConnection.del(...keys);
    logger.debug(`Invalidated ${keys.length} variable indexes`, {
      originatorType,
      originatorId
    });
  }
};

module.exports = {
  getRuleChainsForOriginator,
  buildIndexForOriginator,
  invalidateOriginator,
  getRuleChainsForSensor: (sensorId, vars) => 
    getRuleChainsForOriginator('sensor', sensorId, vars),
  getRuleChainsForDevice: (deviceId, vars) => 
    getRuleChainsForOriginator('device', deviceId, vars),
  invalidateSensor: (sensorId) => 
    invalidateOriginator('sensor', sensorId),
  invalidateDevice: (deviceId) => 
    invalidateOriginator('device', deviceId)
};
```

**Key Changes:**
- ‚úÖ Separate `KEY_PREFIX_SENSOR` and `KEY_PREFIX_DEVICE`
- ‚úÖ Generic `buildIndexForOriginator(type, id)` function
- ‚úÖ Filter nodes by `sourceType` in query
- ‚úÖ Convenience wrappers for sensors and devices
- ‚úÖ Proper logging with originator type

### **Part 3: Event Bus Integration**

```javascript
// src/ruleEngine/core/RuleEngineEventBus.js

const emit = async (eventType, payload, options = {}) => {
  const { sensorUUID, dataStreamId, telemetryDataId } = payload;
  
  let variableNames = [];
  
  if (telemetryDataId) {
    const telemetry = await TelemetryData.findByPk(telemetryDataId);
    if (telemetry && telemetry.variableName) {
      variableNames = [telemetry.variableName];
    }
  }
  
  if (variableNames.length === 0) {
    logger.debug(`No variables for sensor ${sensorUUID}, skipping rule engine`);
    return { 
      rejected: false, 
      skipped: true, 
      reason: 'no-variables' 
    };
  }
  
  const ruleChainIds = await RuleChainIndex.getRuleChainsForSensor(
    sensorUUID,
    variableNames
  );
  
  if (ruleChainIds.length === 0) {
    logger.debug(`No matching rules for sensor ${sensorUUID} variables [${variableNames}]`);
    return { 
      rejected: false, 
      skipped: true, 
      reason: 'no-matching-rules' 
    };
  }
  
  const priority = determinePriority(eventType, options.priority);
  const queueCounts = await getQueueCounts();
  const backpressureCheck = backpressureManager.shouldAcceptEvent(queueCounts, priority);
  
  if (!backpressureCheck.accept) {
    return {
      rejected: true,
      reason: backpressureCheck.reason,
      queueDepth: backpressureCheck.queueDepth
    };
  }
  
  const job = await ruleEngineQueue.add(
    'process-telemetry',
    {
      eventType,
      sensorUUID,
      variableNames,
      ruleChainIds,
      dataStreamId,
      telemetryDataId
    },
    { priority }
  );
  
  logger.debug(`Queued ${ruleChainIds.length} rule chains for sensor ${sensorUUID}`, {
    variables: variableNames,
    ruleChainIds,
    jobId: job.id
  });
  
  return { rejected: false, job, queueDepth: queueCounts.waiting };
};
```

---

### **Part 4: Optional Pre-Build on Startup**

```javascript
// src/ruleEngine/indexing/IndexPrebuilder.js (NEW)

const RuleChainIndex = require('./RuleChainIndex');
const { RuleChainNode } = require('../../models/initModels');
const logger = require('../../utils/logger');

const prebuildAllIndexes = async () => {
  const startTime = Date.now();
  logger.info('Pre-building variable-level indexes...');
  
  const nodes = await RuleChainNode.findAll({
    where: { type: 'filter' },
    attributes: ['ruleChainId', 'config']
  });
  
  const sensorVariableIndex = new Map();
  
  nodes.forEach((node) => {
    const config = typeof node.config === 'string' 
      ? JSON.parse(node.config) 
      : node.config;
    
    const extractUUIDs = (expr) => {
      if (expr.type && expr.expressions) {
        expr.expressions.forEach(extractUUIDs);
      } else if (expr.UUID) {
        const varName = expr.key;
        if (varName) {
          const key = `${expr.UUID}:${varName}`;
          if (!sensorVariableIndex.has(key)) {
            sensorVariableIndex.set(key, new Set());
          }
          sensorVariableIndex.get(key).add(node.ruleChainId);
        }
      }
    };
    
    extractUUIDs(config);
  });
  
  const pipeline = redisConnection.pipeline();
  let indexCount = 0;
  
  for (const [key, ruleChainIds] of sensorVariableIndex) {
    const redisKey = `rulechain:var:${key}`;
    pipeline.set(
      redisKey, 
      JSON.stringify(Array.from(ruleChainIds)), 
      'EX', 
      7200
    );
    indexCount++;
  }
  
  await pipeline.exec();
  
  const duration = Date.now() - startTime;
  logger.info(`Pre-built ${indexCount} variable-level indexes in ${duration}ms`);
  
  return { indexCount, duration };
};

module.exports = { prebuildAllIndexes };
```

**Usage in server.js:**
```javascript
// src/server.js
if (process.env.PREBUILD_RULE_CHAIN_INDEXES === 'true') {
  const { prebuildAllIndexes } = require('./ruleEngine/indexing/IndexPrebuilder');
  prebuildAllIndexes().catch(err => {
    logger.error('Failed to pre-build indexes', err);
  });
}
```

### Implementation Plan

#### Day 1: Variable-Level Index + MySQL Optimization
**Morning (4 hours):**
1. ‚úÖ Implement `buildIndexForSensor` with variable-level indexing
2. ‚úÖ Update `getRuleChainsForSensor` to accept `variableNames` parameter
3. ‚úÖ Update `invalidateSensor` to handle variable-level keys
4. ‚úÖ Unit tests for index building

**Afternoon (4 hours):**
5. ‚úÖ Update `RuleEngineEventBus.emit` to extract and pass variable names
6. ‚úÖ Handle edge cases (no variables, no matching rules)
7. ‚úÖ Integration tests for event bus
8. ‚úÖ Performance benchmarks (before/after)

#### Day 2: Pre-Build + Documentation
**Morning (3 hours):**
1. ‚úÖ Create `IndexPrebuilder.js` with `prebuildAllIndexes`
2. ‚úÖ Add startup hook in `server.js`
3. ‚úÖ Add feature flag `PREBUILD_RULE_CHAIN_INDEXES`
4. ‚úÖ Test startup with 1000+ variable indexes

**Afternoon (5 hours):**
5. ‚úÖ Comprehensive testing (unit + integration + performance)
6. ‚úÖ Document expected metrics (latency + execution reduction)
7. ‚úÖ Create `INDEX-OPTIMIZATION.md` guide
8. ‚úÖ Update environment variable documentation
9. ‚úÖ Code review and cleanup

### Files to Modify/Create

**Modified**:
- `src/ruleEngine/indexing/RuleChainIndex.js` (variable-level index)
- `src/ruleEngine/core/RuleEngineEventBus.js` (pass variables)
- `src/controllers/dataStreamController.js` (extract variables)
- `src/server.js` (optional pre-build hook)
- `src/config/index.js` (feature flag)

**Created**:
- `src/ruleEngine/indexing/IndexPrebuilder.js` (pre-build logic)
- `tests/unit/ruleChainIndex.test.js` (comprehensive tests)
- `tests/unit/ruleEngineEventBus.test.js` (event bus with variables)
- `tests/performance/indexOptimization.benchmark.js` (benchmarks)
- `docs/INDEX-OPTIMIZATION.md` (implementation guide)
- `docs/VARIABLE-LEVEL-FILTERING.md` (architecture explanation)

### Testing Strategy

**Unit Tests**:
```javascript
describe('Variable-Level RuleChainIndex', () => {
  it('should build index with variable names as keys');
  it('should return rule chains matching specific variables');
  it('should return empty array when no variables provided');
  it('should handle sensors with no matching rule chains');
  it('should handle multiple variables in one query');
  it('should extract variables from nested AND/OR expressions');
  it('should cache results with correct TTL');
  it('should invalidate all variable indexes for a sensor');
  it('should rebuild index on cache miss');
  it('should handle database connection errors gracefully');
});

describe('Event Bus Variable Filtering', () => {
  it('should extract variable name from telemetry data');
  it('should skip rule engine when no variables present');
  it('should skip when no matching rules found');
  it('should queue only relevant rule chains');
  it('should pass variable names to worker job');
});
```

**Performance Benchmarks**:
```javascript
describe('Performance Benchmarks', () => {
  it('cache miss - before: ~150ms', async () => {
    // Test with 1000 filter nodes, old approach
  });
  
  it('cache miss - after: <15ms', async () => {
    // Test with variable-level index
  });
  
  it('execution reduction: 50-80%', async () => {
    // Simulate 100 telemetry events
    // Measure: old approach triggers 80 rule chains
    // New approach triggers 20 rule chains (75% reduction)
  });
  
  it('pre-build all indexes: <10s for 10000 variables', async () => {
    // Startup time test
  });
});
```

**Integration Tests**:
```javascript
describe('End-to-End Variable Filtering', () => {
  it('should only trigger rules for matching variables', async () => {
    // Create sensor with temperature and humidity rules
    // Send only temperature data
    // Verify: only temperature rule chain executed
  });
  
  it('should handle multiple variables in one telemetry event', async () => {
    // Send {temperature: 25, humidity: 60}
    // Verify: both rule chains triggered
  });
  
  it('should skip execution when variable not in any rule', async () => {
    // Send {pressure: 1013} (no rules for pressure)
    // Verify: zero rule chains triggered
  });
});
```

### Environment Variables

```bash
# Variable-level index optimization
PREBUILD_RULE_CHAIN_INDEXES=false  # Pre-build on startup (optional)
INDEX_PREBUILD_BATCH_SIZE=100      # Batch size for pre-building
INDEX_CACHE_TTL_SECONDS=3600       # Redis cache TTL (1 hour)

# Logging
LOG_VARIABLE_FILTERING=false       # Debug log for variable filtering
```

### Risks & Mitigation

| Risk | Mitigation |
|------|------------|
| MySQL JSON functions slower than expected | Add generated column index (future optimization) |
| Pre-build increases startup time too much | Make it optional with feature flag (default: false) |
| Filters with no "key" field break indexing | Skip filters without variables, handle gracefully |
| Complex AND/OR expressions miss variables | Extract all variables recursively from nested expressions |
| Telemetry without variable name | Skip rule engine, log warning for investigation |

### Success Metrics

**Before**:
- Cache miss latency: 150ms (p95)
- First-time sensor query: 200ms
- Memory per cache miss: 8MB
- Rule executions per 100 telemetry events: 80 (many irrelevant)

**After**:
- Cache miss latency: <15ms (p95) ‚úÖ **(10x improvement)**
- First-time sensor query: <20ms ‚úÖ
- Memory per cache miss: <1MB ‚úÖ
- Rule executions per 100 telemetry events: 20-30 ‚úÖ **(70% reduction)**

**Combined Impact**:
- **Latency**: 10x faster
- **Efficiency**: 70% fewer executions
- **Queue capacity**: 3x more effective throughput
- **Database load**: 90% reduction in collection queries

---

## üèóÔ∏è **Architecture Explanation: Variable-Level Filtering**

### Why This Approach?

**Inspired by ThingsBoard** ([see their architecture](https://thingsboard.io/)), leading IoT platforms use **multi-dimensional routing** to prevent unnecessary processing:

1. **Device/Sensor ID** - Which device sent the data?
2. **Message Type** - What kind of event is it?
3. **Data Keys** - Which variables are present in the payload?

### Traditional Approach (Current)

```
Telemetry Received ‚Üí Find All Rules for Sensor ‚Üí Queue All Rules
                                                    ‚Üì
                                            Execute All Rules
                                            (Even if data missing!)
```

**Problem**: If sensor has 10 rule chains but only 3 use "temperature", sending temperature data still queues all 10.

### Variable-Level Approach (New)

```
Telemetry Received ‚Üí Extract Variable Names ‚Üí Find Rules Using Those Variables
     ‚Üì                        ‚Üì                           ‚Üì
{"temperature": 25}     ["temperature"]         [RuleChain #1, #3]
                                                    ‚Üì
                                            Queue ONLY Relevant Rules
```

**Result**: Only 2 rule chains queued instead of 10 (80% reduction!)

### Real-World Example

**Setup:**
```javascript
// Sensor "abc123" has these rule chains:
Rule Chain #1: temperature > 30 ‚Üí Turn on AC
Rule Chain #2: humidity > 70 ‚Üí Turn on dehumidifier  
Rule Chain #3: temperature < 15 ‚Üí Turn on heater
Rule Chain #4: motion == true ‚Üí Turn on lights
Rule Chain #5: temperature > 25 AND humidity > 60 ‚Üí Alert
```

**Scenario 1: Receive temperature data**
```javascript
// Incoming: {"temperature": 28}
// Variables: ["temperature"]

// Index lookup:
rulechain:var:abc123:temperature ‚Üí [1, 3, 5]

// Result: Queue only 3 rule chains (not all 5)
// Savings: 40% fewer executions
```

**Scenario 2: Receive motion data**
```javascript
// Incoming: {"motion": true}
// Variables: ["motion"]

// Index lookup:
rulechain:var:abc123:motion ‚Üí [4]

// Result: Queue only 1 rule chain
// Savings: 80% fewer executions
```

**Scenario 3: Receive pressure data (no rules)**
```javascript
// Incoming: {"pressure": 1013}
// Variables: ["pressure"]

// Index lookup:
rulechain:var:abc123:pressure ‚Üí []

// Result: Skip rule engine entirely!
// Savings: 100% (zero executions)
```

### Index Structure

**Redis Keys:**
```
rulechain:var:{sensorUUID}:{variableName} ‚Üí [ruleChainIds]

Examples:
rulechain:var:abc123:temperature ‚Üí [1, 3, 5]
rulechain:var:abc123:humidity ‚Üí [2, 5]
rulechain:var:abc123:motion ‚Üí [4]
```

**Lookup Logic:**
1. Receive telemetry with variables: `["temperature", "humidity"]`
2. Check Redis:
   - `rulechain:var:abc123:temperature` ‚Üí `[1, 3, 5]`
   - `rulechain:var:abc123:humidity` ‚Üí `[2, 5]`
3. Combine (unique): `[1, 2, 3, 5]`
4. Queue only these 4 rule chains (not all 5)

### Why This Is Better Than Sensor-Level Index

| Approach | Index Key | Rule Chains Queued | Efficiency |
|----------|-----------|-------------------|------------|
| **Sensor-Level** (old) | `rulechain:sensor:abc123` | All 5 | 20% (1/5 relevant) |
| **Variable-Level** (new) | `rulechain:var:abc123:temperature` | Only 3 | 100% (3/3 relevant) |

### Edge Cases Handled

1. **No variables in telemetry** ‚Üí Skip rule engine, log warning
2. **Variable not in any rule** ‚Üí Return empty array, skip execution
3. **Complex AND/OR expressions** ‚Üí Extract all variables recursively
4. **Cache miss** ‚Üí Rebuild entire sensor index with all variables
5. **Filter without "key" field** ‚Üí Skip during indexing (e.g., device filters)

### No Backwards Compatibility Needed

Since the system is still in development with no production deployments, we can implement this as a **clean, simplified solution** without backwards compatibility fallbacks:

- ‚úÖ Single code path (easier to test)
- ‚úÖ Forces calling code to always pass variables (contract enforcement)
- ‚úÖ Cleaner implementation
- ‚úÖ Faster development
- ‚úÖ Can add compatibility later if needed

---

# üé´ **Issue #2: Add Rule Execution Timeouts**

## JIRA Description

### Title
`[P1] Add Rule Execution Timeouts with Structured Error Codes - Prevent Hanging Jobs`

### Type
`Reliability Enhancement + Observability`

### Priority
`üü† High (P1)`

### Affected Components
- `src/services/ruleChainService.js`
- `src/ruleEngine/worker/RuleEngineWorker.js`
- `src/ruleEngine/core/RuleEngineQueue.js`

### Problem Statement

**Current Behavior:**
Rule chains can hang indefinitely if:
1. Database queries timeout without error
2. `_collectSensorData` waits for slow sensor queries
3. `_collectDeviceData` waits for slow device queries
4. External API calls in custom actions never return

```javascript
// ‚ùå No timeout on data collection
async trigger(sensorUUID = null) {
  const [sensorData, deviceData] = await Promise.all([
    this._collectSensorData(sensorReqs),  // Can hang forever
    this._collectDeviceData(deviceReqs)   // Can hang forever
  ]);
  
  const executionResult = await this.execute(ruleChain.id, rawData);  // No timeout
}
```

**Impact**:
- Worker processes become unresponsive
- Queue jobs pile up behind hanging job
- Other rule chains can't execute
- Manual intervention required to kill workers

### Acceptance Criteria

- [ ] **AC1**: Rule execution times out after configurable duration (default 30s)
- [ ] **AC2**: Sensor/device data collection has individual timeouts (default 5s each)
- [ ] **AC3**: Timeout errors logged with full context (ruleChainId, sensorUUID, duration)
- [ ] **AC4**: Timed-out jobs marked as "failed" with clear reason
- [ ] **AC5**: Structured error codes for timeout classification
- [ ] **AC6**: Metrics tracked for timeout frequency by error code
- [ ] **AC7**: Configurable via environment variables
- [ ] **AC8**: Unit tests cover all timeout scenarios

### Structured Error Codes (NEW)

**Why**: Enable precise monitoring, alerting, and SLA tracking

```javascript
// Error code classification
ERROR_CODES = {
  DATA_COLLECTION_TIMEOUT: 'DATA_COLLECTION_TIMEOUT',      // Sensor/device queries
  RULE_EXECUTION_TIMEOUT: 'RULE_EXECUTION_TIMEOUT',        // Rule chain execution
  WORKER_TIMEOUT: 'WORKER_TIMEOUT',                        // BullMQ job timeout
  EXTERNAL_ACTION_TIMEOUT: 'EXTERNAL_ACTION_TIMEOUT'       // Custom action APIs
}
```

**Benefits:**
- ‚úÖ Alert rules per timeout type
- ‚úÖ SLA reporting by error code
- ‚úÖ Faster incident debugging
- ‚úÖ Metrics: `rule_timeout_total{error_code="DATA_COLLECTION_TIMEOUT"}`

### Technical Approach

#### **Solution: Multi-Level Timeout Strategy**

**Level 1: Data Collection Timeouts with Error Codes**
```javascript
// src/services/ruleChainService.js
// src/utils/TimeoutError.js (NEW)
class TimeoutError extends Error {
  constructor(message, code, context = {}) {
    super(message);
    this.name = 'TimeoutError';
    this.code = code;
    this.context = context;
    this.timestamp = new Date().toISOString();
  }
}

const ERROR_CODES = {
  DATA_COLLECTION_TIMEOUT: 'DATA_COLLECTION_TIMEOUT',
  RULE_EXECUTION_TIMEOUT: 'RULE_EXECUTION_TIMEOUT',
  WORKER_TIMEOUT: 'WORKER_TIMEOUT',
  EXTERNAL_ACTION_TIMEOUT: 'EXTERNAL_ACTION_TIMEOUT'
};

const _collectSensorDataWithTimeout = async (sensorReqs, timeout = 5000) => {
  return Promise.race([
    this._collectSensorData(sensorReqs),
    new Promise((_, reject) =>
      setTimeout(() => {
        reject(new TimeoutError(
          `Sensor data collection timeout after ${timeout}ms`,
          ERROR_CODES.DATA_COLLECTION_TIMEOUT,
          { sensorCount: sensorReqs.size, timeout }
        ));
      }, timeout)
    )
  ]);
};

const _collectDeviceDataWithTimeout = async (deviceReqs, timeout = 5000) => {
  return Promise.race([
    this._collectDeviceData(deviceReqs),
    new Promise((_, reject) =>
      setTimeout(() => {
        reject(new TimeoutError(
          `Device data collection timeout after ${timeout}ms`,
          ERROR_CODES.DATA_COLLECTION_TIMEOUT,
          { deviceCount: deviceReqs.size, timeout }
        ));
      }, timeout)
    )
  ]);
};

module.exports = { TimeoutError, ERROR_CODES };
```

**Level 2: Rule Execution Timeout with Error Codes**
```javascript
const executeWithTimeout = async (ruleChainId, rawData, timeout = 30000) => {
  return Promise.race([
    this.execute(ruleChainId, rawData),
    new Promise((_, reject) =>
      setTimeout(() => {
        reject(new TimeoutError(
          `Rule chain execution timeout after ${timeout}ms`,
          ERROR_CODES.RULE_EXECUTION_TIMEOUT,
          { ruleChainId, timeout }
        ));
      }, timeout)
    )
  ]);
};
```

**Level 3: Worker Job Timeout (BullMQ)**
```javascript
// src/ruleEngine/worker/RuleEngineWorker.js

ruleEngineWorker = new Worker(
  queueName,
  async (job) => {
    const startTime = Date.now();
    const timeout = parseInt(process.env.RULE_EXECUTION_TIMEOUT || '30000', 10);
    
    try {
      const result = await Promise.race([
        processJob(job),
        new Promise((_, reject) =>
          setTimeout(() => reject(new Error('Job timeout')), timeout)
        )
      ]);
      
      return result;
    } catch (error) {
      const duration = Date.now() - startTime;
      logger.error('Rule execution failed', {
        jobId: job.id,
        ruleChainId: job.data.ruleChainId,
        sensorUUID: job.data.sensorUUID,
        duration,
        error: error.message,
        timedOut: error.message.includes('timeout')
      });
      throw error;
    }
  },
  {
    connection: redisConnection,
    concurrency: config.ruleEngine.workerConcurrency,
    // BullMQ built-in timeout
    lockDuration: 60000,  // Max 60s lock
    maxStalledCount: 2    // Fail after 2 stalls
  }
);
```

**Level 4: Enhanced Error Handling with Metrics**
```javascript
async trigger(sensorUUID = null) {
  const startTime = Date.now();
  const timeout = parseInt(process.env.RULE_TRIGGER_TIMEOUT || '30000', 10);
  
  try {
    const dataCollectionTimeout = parseInt(process.env.DATA_COLLECTION_TIMEOUT || '5000', 10);
    
    const [sensorData, deviceData] = await Promise.all([
      this._collectSensorDataWithTimeout(sensorReqs, dataCollectionTimeout)
        .catch(err => {
          if (err.code === ERROR_CODES.DATA_COLLECTION_TIMEOUT) {
            logger.warn('Sensor data collection timed out', err.context);
            metricsClient.timeoutCounter.labels(err.code).inc();
          }
          return [];
        }),
      this._collectDeviceDataWithTimeout(deviceReqs, dataCollectionTimeout)
        .catch(err => {
          if (err.code === ERROR_CODES.DATA_COLLECTION_TIMEOUT) {
            logger.warn('Device data collection timed out', err.context);
            metricsClient.timeoutCounter.labels(err.code).inc();
          }
          return [];
        })
    ]);
    
    const executionResult = await this.executeWithTimeout(
      ruleChain.id,
      { sensorData, deviceData },
      timeout - (Date.now() - startTime)
    );
    
    return executionResult;
  } catch (error) {
    const duration = Date.now() - startTime;
    
    if (error.code) {
      logger.error('Rule chain execution failed', {
        errorCode: error.code,
        ruleChainId: ruleChain.id,
        sensorUUID,
        duration,
        context: error.context
      });
      
      metricsClient.timeoutCounter.labels(error.code).inc();
      metricsClient.timeoutDuration.labels(error.code).observe(duration / 1000);
    }
    
    throw error;
  }
}
```

**Metrics Definition:**
```javascript
// src/utils/metricsClient.js
const timeoutCounter = new promClient.Counter({
  name: 'rule_timeout_total',
  help: 'Total rule execution timeouts by error code',
  labelNames: ['error_code']
});

const timeoutDuration = new promClient.Histogram({
  name: 'rule_timeout_duration_seconds',
  help: 'Duration before timeout by error code',
  labelNames: ['error_code'],
  buckets: [1, 5, 10, 30, 60]
});
```

### Implementation Plan

#### Day 1: Core Implementation
1. ‚úÖ Add timeout wrapper functions
2. ‚úÖ Update `trigger` method with timeouts
3. ‚úÖ Add environment variable configuration
4. ‚úÖ Implement timeout error handling
5. ‚úÖ Add logging for timeout events

#### Day 1 (afternoon): Worker Integration
1. ‚úÖ Update BullMQ worker configuration
2. ‚úÖ Add timeout metrics tracking
3. ‚úÖ Test with intentionally slow queries
4. ‚úÖ Integration tests

### Files to Modify/Create

**Modified**:
- `src/services/ruleChainService.js` (timeout logic)
- `src/ruleEngine/worker/RuleEngineWorker.js` (worker timeouts)
- `src/config/index.js` (timeout configs)

**Created**:
- `tests/unit/ruleExecutionTimeout.test.js`
- `tests/integration/slowQueryTimeout.test.js`
- `docs/RULE-EXECUTION-TIMEOUTS.md`

### Environment Variables

```bash
# Rule execution timeouts (milliseconds)
RULE_EXECUTION_TIMEOUT=30000        # Overall rule chain execution (30s)
DATA_COLLECTION_TIMEOUT=5000        # Sensor/device data collection (5s)
RULE_TRIGGER_TIMEOUT=30000          # Trigger method timeout (30s)
WORKER_LOCK_DURATION=60000          # BullMQ lock duration (60s)
```

### Testing Strategy

**Unit Tests**:
```javascript
describe('Rule Execution Timeouts', () => {
  it('should timeout sensor data collection after 5s');
  it('should timeout device data collection after 5s');
  it('should timeout rule execution after 30s');
  it('should continue with empty data if collection times out');
  it('should log timeout events with full context');
  it('should track timeout metrics');
});
```

**Integration Tests**:
```javascript
describe('Timeout Integration', () => {
  it('should handle database query timeout', async () => {
    // Mock slow database query
    jest.spyOn(Sensor, 'findOne').mockImplementation(() =>
      new Promise(resolve => setTimeout(resolve, 10000))
    );
    
    const result = await ruleChainService.trigger(sensorUUID);
    expect(result).toHaveProperty('error');
    expect(result.error).toContain('timeout');
  });
});
```

### Success Metrics

**Before**:
- Hanging jobs: 2-5% of total
- Worker recovery: Manual intervention required
- Average time to detect hang: 10+ minutes

**After**:
- Hanging jobs: 0% ‚úÖ
- Worker recovery: Automatic (timeout + retry)
- Average time to detect timeout: <30s ‚úÖ

---

# üé´ **Issue #3: Add Prometheus Metrics**

## JIRA Description

### Title
`[P1] Complete Prometheus Metrics Integration for Full Observability`

### Type
`Observability Enhancement`

### Priority
`üü† High (P1)`

### Current Status
**Partially Implemented** (P0 backpressure work)

### What Exists (from P0)
- ‚úÖ Queue metrics endpoint: `GET /api/v1/metrics/queue`
- ‚úÖ Prometheus format: `GET /api/v1/metrics/prometheus`
- ‚úÖ Health checks: `GET /api/v1/health`
- ‚úÖ Backpressure metrics
- ‚úÖ Queue depth, workers, circuit state

### What's Missing (P1 Scope)

1. **Rule Execution Metrics**
   - Execution duration (histogram)
   - Success/failure rate
   - Nodes executed per chain
   - Filter pass/fail rates
   - Action execution counts

2. **Data Collection Metrics**
   - Sensor data collection time
   - Device data collection time
   - Collection errors

3. **System Metrics**
   - HTTP request duration
   - API endpoint latency
   - Database query performance
   - Redis operation performance

4. **Business Metrics**
   - Telemetry data ingestion rate
   - Rule chains triggered per hour
   - Notifications sent (by protocol)
   - Device state changes

### Acceptance Criteria

- [ ] **AC1**: All rule execution metrics exposed in Prometheus format
- [ ] **AC2**: System metrics (HTTP, DB, Redis) tracked
- [ ] **AC3**: Business metrics for monitoring SLAs
- [ ] **AC4**: Cardinality control - avoid high-cardinality labels (sensorUUID, deviceUUID)
- [ ] **AC5**: Grafana dashboard JSON provided
- [ ] **AC6**: Alert rules defined for critical metrics
- [ ] **AC7**: Documentation with example queries and cardinality warnings
- [ ] **AC8**: Metrics don't impact performance (< 1ms overhead)

### üî¥ CRITICAL: Cardinality Control

**Problem**: Using high-cardinality labels (sensorUUID, deviceUUID) can create **millions of time series** in Prometheus:

```javascript
// ‚ùå BAD - High cardinality (10k sensors √ó 100 rule chains = 1M series!)
const telemetryIngestionRate = new promClient.Counter({
  name: 'telemetry_ingestion_total',
  labelNames: ['sensorUUID', 'organizationId']  // DON'T DO THIS
});
```

**Impact:**
- Prometheus query timeouts
- High memory usage (gigabytes)
- Slow dashboard loading
- Hits Prometheus cardinality limits (default 10M series)

**Solution**: Use **bounded** labels only

```javascript
// ‚úÖ GOOD - Low cardinality (bounded by rule chains/organizations)
const ruleExecutionTotal = new promClient.Counter({
  name: 'rule_execution_total',
  labelNames: ['ruleChainId', 'status']  // ~200 series max
});

const telemetryIngestionRate = new promClient.Counter({
  name: 'telemetry_ingestion_total',
  labelNames: ['organizationId']  // ~10-100 series
});

// For per-sensor metrics ‚Üí use structured logging
logger.info('telemetry_ingested', {
  sensorUUID,
  organizationId,
  variableName,
  value
});
```

**ThingsBoard Approach**: They avoid sensor/device UUIDs in Prometheus and use:
- Aggregated counters by organization
- Structured logs for per-device metrics
- Distributed tracing for detailed analysis

### Technical Approach

#### **Solution: Comprehensive Metrics with `prom-client`**

**Step 1: Initialize Metrics Client (Cardinality-Safe)**
```javascript
// src/utils/metricsClient.js
const promClient = require('prom-client');

const register = new promClient.Registry();
promClient.collectDefaultMetrics({ register });

// ‚úÖ GOOD - Bounded cardinality
const ruleExecutionDuration = new promClient.Histogram({
  name: 'rule_execution_duration_seconds',
  help: 'Duration of rule chain execution',
  labelNames: ['ruleChainId', 'status'],  // ~100 rule chains √ó 2 statuses = 200 series
  buckets: [0.01, 0.05, 0.1, 0.5, 1, 2, 5, 10]
});

const ruleExecutionTotal = new promClient.Counter({
  name: 'rule_execution_total',
  help: 'Total rule chain executions',
  labelNames: ['ruleChainId', 'status']  // Bounded cardinality
});

const dataCollectionDuration = new promClient.Histogram({
  name: 'data_collection_duration_seconds',
  help: 'Duration of sensor/device data collection',
  labelNames: ['type', 'status'],  // Only 2 types √ó 2 statuses = 4 series
  buckets: [0.001, 0.005, 0.01, 0.05, 0.1, 0.5, 1]
});

const httpRequestDuration = new promClient.Histogram({
  name: 'http_request_duration_seconds',
  help: 'Duration of HTTP requests',
  labelNames: ['method', 'route', 'status_code'],  // Bounded by API routes
  buckets: [0.001, 0.005, 0.01, 0.05, 0.1, 0.5, 1, 2]
});

// ‚úÖ GOOD - Aggregated by organization (not per-sensor!)
const telemetryIngestionRate = new promClient.Counter({
  name: 'telemetry_ingestion_total',
  help: 'Total telemetry data points ingested',
  labelNames: ['organizationId']  // ~10-100 orgs = bounded
});

// ‚ùå REMOVED - High cardinality:
// labelNames: ['sensorUUID', 'organizationId']  // Would create 10k+ series!

register.registerMetric(ruleExecutionDuration);
register.registerMetric(ruleExecutionTotal);
register.registerMetric(dataCollectionDuration);
register.registerMetric(httpRequestDuration);
register.registerMetric(telemetryIngestionRate);

module.exports = {
  register,
  ruleExecutionDuration,
  ruleExecutionTotal,
  dataCollectionDuration,
  httpRequestDuration,
  telemetryIngestionRate
};
```

**Cardinality Rules:**
- ‚úÖ Use: ruleChainId, organizationId, status, type
- ‚ùå Avoid: sensorUUID, deviceUUID, userId, telemetryDataId
- üìä Per-device metrics ‚Üí Structured logs + log aggregation tools

**Step 2: Instrument Rule Execution**
```javascript
// src/services/ruleChainService.js
const metricsClient = require('../utils/metricsClient');

async trigger(sensorUUID = null) {
  const startTime = Date.now();
  
  try {
    // ... existing code ...
    
    const result = await this.execute(ruleChain.id, rawData);
    
    // Track success metrics
    const duration = (Date.now() - startTime) / 1000;
    metricsClient.ruleExecutionDuration
      .labels(ruleChain.id.toString(), 'success')
      .observe(duration);
    metricsClient.ruleExecutionTotal
      .labels(ruleChain.id.toString(), 'success')
      .inc();
    
    return result;
  } catch (error) {
    // Track failure metrics
    const duration = (Date.now() - startTime) / 1000;
    metricsClient.ruleExecutionDuration
      .labels(ruleChain.id.toString(), 'failure')
      .observe(duration);
    metricsClient.ruleExecutionTotal
      .labels(ruleChain.id.toString(), 'failure')
      .inc();
    
    throw error;
  }
}
```

**Step 3: HTTP Middleware for Request Metrics**
```javascript
// src/middleware/metricsMiddleware.js
const metricsClient = require('../utils/metricsClient');

const metricsMiddleware = (req, res, next) => {
  const start = Date.now();
  
  res.on('finish', () => {
    const duration = (Date.now() - start) / 1000;
    const route = req.route ? req.route.path : req.path;
    
    metricsClient.httpRequestDuration
      .labels(req.method, route, res.statusCode.toString())
      .observe(duration);
  });
  
  next();
};

module.exports = metricsMiddleware;
```

**Step 4: Enhanced Prometheus Endpoint**
```javascript
// src/routes/metricsRoutes.js (already exists from P0)

// Add to existing endpoint
router.get('/prometheus', async (req, res) => {
  try {
    res.set('Content-Type', metricsClient.register.contentType);
    res.end(await metricsClient.register.metrics());
  } catch (error) {
    res.status(500).json({ error: error.message });
  }
});
```

**Step 5: Grafana Dashboard**
```json
{
  "dashboard": {
    "title": "AEMOS Backend - Rule Engine",
    "panels": [
      {
        "title": "Rule Execution Rate",
        "targets": [{
          "expr": "rate(rule_execution_total[5m])"
        }]
      },
      {
        "title": "Rule Execution Duration (p95)",
        "targets": [{
          "expr": "histogram_quantile(0.95, rate(rule_execution_duration_seconds_bucket[5m]))"
        }]
      },
      {
        "title": "Queue Depth",
        "targets": [{
          "expr": "rule_engine_queue_total_pending"
        }]
      }
    ]
  }
}
```

### Implementation Plan

#### Day 1: Core Metrics
1. ‚úÖ Create `metricsClient.js` with all metric definitions
2. ‚úÖ Instrument rule execution in `ruleChainService.js`
3. ‚úÖ Instrument data collection methods
4. ‚úÖ Add HTTP metrics middleware
5. ‚úÖ Test metrics endpoint

#### Day 2: Integration & Testing
1. ‚úÖ Add telemetry ingestion metrics
2. ‚úÖ Add notification metrics (MQTT, CoAP, Socket.IO)
3. ‚úÖ Integration tests
4. ‚úÖ Load test to verify low overhead

#### Day 3: Dashboards & Documentation
1. ‚úÖ Create Grafana dashboard JSON
2. ‚úÖ Define Prometheus alert rules
3. ‚úÖ Write comprehensive documentation
4. ‚úÖ Example queries for common scenarios

### Files to Modify/Create

**Modified**:
- `src/routes/metricsRoutes.js` (enhance Prometheus endpoint)
- `src/services/ruleChainService.js` (add metrics)
- `src/controllers/dataStreamController.js` (add ingestion metrics)
- `src/server.js` (add HTTP metrics middleware)

**Created**:
- `src/utils/metricsClient.js` (central metrics)
- `src/middleware/metricsMiddleware.js` (HTTP middleware)
- `grafana/dashboards/aemos-backend.json`
- `prometheus/alerts/aemos-rules.yml`
- `docs/PROMETHEUS-METRICS.md`

### Environment Variables

```bash
# Metrics configuration
ENABLE_METRICS=true
METRICS_COLLECT_DEFAULT=true  # Node.js default metrics
METRICS_HISTOGRAM_BUCKETS=0.01,0.05,0.1,0.5,1,2,5,10
```

### Testing Strategy

**Performance Test**:
```javascript
describe('Metrics Performance', () => {
  it('should add < 1ms overhead per request', async () => {
    const iterations = 10000;
    const start = Date.now();
    
    for (let i = 0; i < iterations; i++) {
      metricsClient.ruleExecutionTotal.labels('1', 'success').inc();
    }
    
    const duration = Date.now() - start;
    const avgOverhead = duration / iterations;
    
    expect(avgOverhead).toBeLessThan(0.01); // < 0.01ms per metric
  });
});
```

### Success Metrics

**Coverage**:
- ‚úÖ 15+ custom metrics defined
- ‚úÖ All critical paths instrumented
- ‚úÖ Grafana dashboard with 10+ panels
- ‚úÖ 5+ alert rules defined

**Performance**:
- ‚úÖ Metrics overhead < 1ms per request
- ‚úÖ Prometheus scrape time < 100ms
- ‚úÖ No memory leaks from metrics

---

# üé´ **Issue #4: Validate Rule Chain Config UUIDs**

## JIRA Description

### Title
`[P1] Add UUID Validation for Rule Chain Filter Configs - Security Enhancement`

### Type
`Security / Data Validation`

### Priority
`üü† High (P1)`

### Affected Components
- `src/services/ruleChainService.js`
- `src/controllers/ruleChainController.js`

### Problem Statement

**Current Behavior:**
Rule chain filter nodes accept any string as UUID without validation:

```javascript
// ‚ùå No validation
async createNode(data) {
  const node = await RuleChainNode.create(data);  // data.config can have invalid UUIDs
  return node;
}
```

**Security/Correctness Risks**:
1. **Malformed UUIDs**: Typos never caught (`aaabbb123` vs `aaabbb12`)
2. **SQL Injection**: If used in raw queries (unlikely but possible)
3. **Index Pollution**: Redis cache filled with invalid keys
4. **Silent Failures**: Rules silently never match because UUID is wrong
5. **Debugging Difficulty**: Hard to trace why rules don't execute

**Example Invalid Configs**:
```json
{
  "sourceType": "sensor",
  "UUID": "not-a-valid-uuid",
  "key": "temperature",
  "operator": ">",
  "value": 30
}
```

### Acceptance Criteria

- [ ] **AC1**: All UUIDs in filter configs validated on create/update
- [ ] **AC2**: Clear error messages for invalid UUIDs
- [ ] **AC3**: Supports multiple UUID formats (UUID v4, custom format)
- [ ] **AC4**: Validates nested UUIDs in complex AND/OR expressions
- [ ] **AC5**: Action node device UUIDs also validated
- [ ] **AC6**: Existing invalid configs flagged with audit script
- [ ] **AC7**: Unit tests cover all validation paths

### Technical Approach

#### **Solution: Multi-Layer UUID Validation**

**Step 1: UUID Validation Utility**
```javascript
// src/utils/uuidValidator.js
const { validate: isUUID } = require('uuid');

const UUID_FORMATS = {
  UUID_V4: /^[0-9a-f]{8}-[0-9a-f]{4}-4[0-9a-f]{3}-[89ab][0-9a-f]{3}-[0-9a-f]{12}$/i,
  CUSTOM_HEX: /^[0-9a-f]{8,}$/i  // Your custom format (min 8 hex chars)
};

const validateUUID = (uuid, allowCustomFormat = true) => {
  if (!uuid || typeof uuid !== 'string') {
    return { valid: false, error: 'UUID must be a non-empty string' };
  }
  
  // Check standard UUID v4
  if (isUUID(uuid, 4)) {
    return { valid: true };
  }
  
  // Check custom hex format (if allowed)
  if (allowCustomFormat && UUID_FORMATS.CUSTOM_HEX.test(uuid)) {
    return { valid: true };
  }
  
  return {
    valid: false,
    error: `Invalid UUID format: "${uuid}". Expected UUID v4 or hexadecimal string (min 8 chars)`
  };
};

const validateRuleChainConfig = (config, nodeType) => {
  const errors = [];
  
  if (nodeType === 'filter') {
    // Validate filter expression UUIDs
    const validateExpression = (expr, path = 'config') => {
      if (expr.type && expr.expressions) {
        // Nested AND/OR
        expr.expressions.forEach((subExpr, idx) => {
          validateExpression(subExpr, `${path}.expressions[${idx}]`);
        });
      } else {
        // Leaf node
        if (expr.UUID) {
          const result = validateUUID(expr.UUID);
          if (!result.valid) {
            errors.push({
              path: `${path}.UUID`,
              value: expr.UUID,
              error: result.error
            });
          }
        }
      }
    };
    
    validateExpression(config);
  } else if (nodeType === 'action') {
    // Validate action device UUID
    if (config.command && config.command.deviceUuid) {
      const result = validateUUID(config.command.deviceUuid);
      if (!result.valid) {
        errors.push({
          path: 'config.command.deviceUuid',
          value: config.command.deviceUuid,
          error: result.error
        });
      }
    }
  }
  
  return {
    valid: errors.length === 0,
    errors
  };
};

module.exports = {
  validateUUID,
  validateRuleChainConfig
};
```

**Step 2: Integrate into RuleChainService**
```javascript
// src/services/ruleChainService.js
const { validateRuleChainConfig } = require('../utils/uuidValidator');

async createNode(data) {
  try {
    // Validate config before creating
    if (data.config) {
      const validation = validateRuleChainConfig(data.config, data.type);
      if (!validation.valid) {
        const error = new Error('Invalid rule chain node configuration');
        error.statusCode = 400;
        error.details = validation.errors;
        throw error;
      }
    }
    
    // Check for duplicate name
    const existingNode = await RuleChainNode.findOne({
      where: {
        ruleChainId: data.ruleChainId,
        name: data.name
      }
    });
    
    if (existingNode) {
      const error = new Error('A node with this name already exists in this rule chain');
      error.statusCode = 400;
      throw error;
    }
    
    const node = await RuleChainNode.create(data);
    return node;
  } catch (error) {
    throw error;
  }
}

async updateNode(id, data) {
  try {
    const node = await RuleChainNode.findByPk(id);
    if (!node) {
      throw new Error('Node not found');
    }
    
    // Validate config if being updated
    if (data.config) {
      const validation = validateRuleChainConfig(data.config, data.type || node.type);
      if (!validation.valid) {
        const error = new Error('Invalid rule chain node configuration');
        error.statusCode = 400;
        error.details = validation.errors;
        throw error;
      }
    }
    
    // ... rest of update logic ...
  } catch (error) {
    throw error;
  }
}
```

**Step 3: Enhanced Error Response**
```javascript
// src/controllers/ruleChainController.js
const createNode = async (req, res, next) => {
  try {
    const node = await ruleChainService.createNode(req.body);
    res.status(201).json(node);
  } catch (error) {
    if (error.statusCode === 400 && error.details) {
      return res.status(400).json({
        error: error.message,
        validationErrors: error.details
      });
    }
    next(error);
  }
};
```

**Step 4: Audit Script for Existing Configs**
```javascript
// scripts/audit-rule-chain-uuids.js
const { RuleChainNode } = require('../src/models/initModels');
const { validateRuleChainConfig } = require('../src/utils/uuidValidator');

const auditRuleChainConfigs = async () => {
  console.log('Auditing rule chain node configurations...\n');
  
  const nodes = await RuleChainNode.findAll({
    attributes: ['id', 'ruleChainId', 'type', 'name', 'config']
  });
  
  const invalidNodes = [];
  
  for (const node of nodes) {
    if (!node.config) continue;
    
    const validation = validateRuleChainConfig(node.config, node.type);
    if (!validation.valid) {
      invalidNodes.push({
        nodeId: node.id,
        ruleChainId: node.ruleChainId,
        name: node.name,
        type: node.type,
        errors: validation.errors
      });
    }
  }
  
  if (invalidNodes.length === 0) {
    console.log('‚úÖ All rule chain nodes have valid UUIDs!');
  } else {
    console.log(`‚ùå Found ${invalidNodes.length} nodes with invalid UUIDs:\n`);
    invalidNodes.forEach(node => {
      console.log(`Node ID ${node.nodeId} (${node.name}):`);
      node.errors.forEach(err => {
        console.log(`  - ${err.path}: ${err.error}`);
        console.log(`    Current value: "${err.value}"`);
      });
      console.log('');
    });
  }
  
  process.exit(invalidNodes.length > 0 ? 1 : 0);
};

auditRuleChainConfigs().catch(console.error);
```

### Implementation Plan

#### Day 1: Implementation
1. ‚úÖ Create `uuidValidator.js` utility
2. ‚úÖ Integrate validation into `createNode` and `updateNode`
3. ‚úÖ Enhance error responses in controller
4. ‚úÖ Unit tests for validator
5. ‚úÖ Create audit script

#### Day 1 (afternoon): Rollout
1. ‚úÖ Run audit script on staging
2. ‚úÖ Fix any invalid configs found
3. ‚úÖ Integration tests
4. ‚úÖ Deploy to production
5. ‚úÖ Monitor for validation errors

### Files to Modify/Create

**Modified**:
- `src/services/ruleChainService.js` (add validation)
- `src/controllers/ruleChainController.js` (enhanced errors)

**Created**:
- `src/utils/uuidValidator.js` (validation logic)
- `scripts/audit-rule-chain-uuids.js` (audit script)
- `tests/unit/uuidValidator.test.js`
- `docs/UUID-VALIDATION.md`

### Testing Strategy

**Unit Tests**:
```javascript
describe('UUID Validator', () => {
  it('should accept valid UUID v4');
  it('should accept custom hex format (8+ chars)');
  it('should reject invalid UUIDs');
  it('should validate nested AND/OR expressions');
  it('should validate action device UUIDs');
  it('should provide clear error messages');
});

describe('Rule Chain Service Validation', () => {
  it('should reject creating node with invalid UUID');
  it('should reject updating node with invalid UUID');
  it('should return detailed validation errors');
});
```

### Success Metrics

**Coverage**:
- ‚úÖ 100% of filter nodes validated
- ‚úÖ 100% of action nodes validated
- ‚úÖ Audit script identifies all invalid configs

**Quality**:
- ‚úÖ Clear error messages guide users
- ‚úÖ Zero SQL injection risk
- ‚úÖ Reduced debugging time for UUID issues

---

# üìã **Complete Implementation Roadmap**

## Sprint Planning (7 Days)

### **Week 1: All P1 Issues**

#### **Days 1-2: Issue #1 (Index Optimization)**
- Day 1 AM: MySQL JSON query implementation
- Day 1 PM: Testing and benchmarking
- Day 2 AM: Pre-build index implementation
- Day 2 PM: Migration script, documentation

#### **Day 3: Issue #2 (Timeouts)**
- Day 3 AM: Timeout wrapper functions
- Day 3 PM: Worker integration, testing

#### **Days 4-6: Issue #3 (Prometheus)**
- Day 4: Core metrics implementation
- Day 5: Integration and business metrics
- Day 6: Dashboards, alerts, documentation

#### **Day 7: Issue #4 (UUID Validation)**
- Day 7 AM: Validator implementation
- Day 7 PM: Audit, testing, deployment

---

## üèóÔ∏è **Architecture & Development Strategy**

### Design Principles

1. **Non-Breaking Changes**: All enhancements must be backwards compatible
2. **Feature Flags**: New optimizations behind environment variables
3. **Fail-Safe Defaults**: System continues working if enhancements fail
4. **Comprehensive Testing**: Unit + integration + performance tests
5. **Metrics-Driven**: Every enhancement must be measurable

### Technology Stack

- **Metrics**: `prom-client` library
- **Validation**: `uuid` library + custom regex
- **Timeouts**: `Promise.race` pattern
- **Optimization**: MySQL JSON functions + Redis pre-building

### Dependency Matrix

```
Issue #1 (Index)     ‚Üí Independent
Issue #2 (Timeouts)  ‚Üí Independent
Issue #3 (Metrics)   ‚Üí Partial dependency on #1, #2
Issue #4 (UUID)      ‚Üí Independent
```

**Recommendation**: Can be developed in parallel by multiple devs.

### Testing Strategy

#### Unit Tests
- Target: 90%+ coverage for new code
- Framework: Jest
- Focus: Edge cases, error handling, validation

#### Integration Tests
- Target: All critical paths covered
- Approach: Test with real MySQL + Redis
- Scenarios: Timeouts, cache misses, invalid UUIDs

#### Performance Tests
- Target: Verify 10x improvements
- Tools: Artillery, k6, or custom benchmarks
- Metrics: Latency (p50, p95, p99), throughput

#### Load Tests
- Target: 10k req/s sustained
- Duration: 1 hour minimum
- Monitor: Queue depth, memory, CPU, DB connections

### Deployment Strategy

#### Phase 1: Staging Deployment
1. Deploy all P1 enhancements to staging
2. Run comprehensive tests (unit + integration + load)
3. Monitor for 48 hours
4. Fix any issues discovered

#### Phase 2: Canary Production Deployment
1. Deploy to 10% of production traffic
2. Monitor metrics (errors, latency, timeouts)
3. Gradual rollout: 10% ‚Üí 25% ‚Üí 50% ‚Üí 100%
4. Each step: 24 hour monitoring period

#### Phase 3: Full Production Deployment
1. Enable all feature flags
2. Run load tests on production (controlled)
3. Monitor for 1 week
4. Document lessons learned

### Rollback Plan

Each enhancement has independent rollback:
- **Index Optimization**: Disable `USE_OPTIMIZED_INDEX_QUERY` flag
- **Timeouts**: Increase timeout values or disable
- **Metrics**: Disable `ENABLE_METRICS` flag
- **UUID Validation**: Disable validation temporarily (not recommended)

### Monitoring & Alerting

**Key Metrics to Watch**:
- Cache miss latency (should decrease 10x)
- Timeout frequency (should be < 0.1%)
- Prometheus scrape duration (should be < 100ms)
- UUID validation errors (should decrease over time)

**Alerts to Configure**:
- Index cache miss latency > 50ms
- Rule execution timeout > 5% of requests
- Prometheus scrape duration > 200ms
- UUID validation error rate > 1%

---

## üìä **Success Criteria**

### Performance Improvements
- [ ] Cache miss latency: 150ms ‚Üí <15ms (10x improvement) ‚úÖ
- [ ] Zero hanging rule executions ‚úÖ
- [ ] Metrics overhead < 1ms per request ‚úÖ

### Reliability Improvements
- [ ] 100% of rule executions have timeouts ‚úÖ
- [ ] 100% of UUIDs validated ‚úÖ
- [ ] Automatic recovery from slow queries ‚úÖ

### Observability Improvements
- [ ] 15+ Prometheus metrics exposed ‚úÖ
- [ ] Grafana dashboard operational ‚úÖ
- [ ] Alert rules configured ‚úÖ

### Code Quality
- [ ] 90%+ test coverage for new code ‚úÖ
- [ ] Zero linter errors ‚úÖ
- [ ] Complete documentation (4 new docs) ‚úÖ

---

## üìö **Documentation Deliverables**

1. `docs/INDEX-OPTIMIZATION.md` - Performance tuning guide
2. `docs/RULE-EXECUTION-TIMEOUTS.md` - Timeout configuration
3. `docs/PROMETHEUS-METRICS.md` - Metrics reference
4. `docs/UUID-VALIDATION.md` - Validation rules
5. `grafana/dashboards/aemos-backend.json` - Grafana dashboard
6. `prometheus/alerts/aemos-rules.yml` - Alert rules

---

## üéØ **Ready to Proceed?**

Once you approve this plan, I'll begin implementation in this order:

1. ‚úÖ **Issue #1**: Index Optimization (2 days)
2. ‚úÖ **Issue #2**: Rule Execution Timeouts (1 day)
3. ‚úÖ **Issue #3**: Complete Prometheus Metrics (3 days)
4. ‚úÖ **Issue #4**: UUID Validation (1 day)

**Total**: 7 days of focused development

Do you approve this approach? Any changes or clarifications needed before we begin coding?
